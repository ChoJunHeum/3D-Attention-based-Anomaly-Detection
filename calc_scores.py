import math

import torch
import torch.nn as nn

import numpy as np
from sklearn import metrics


def log10(t):
    """
    Calculates the base-10 tensorboard_log of each element in t.
    @param t: The tensor from which to calculate the base-10 tensorboard_log.
    @return: A tensor with the base-10 tensorboard_log of each element in t.
    """
    numerator = torch.log(t)
    device = str(t.device)
    denominator = torch.log(torch.FloatTensor([10.])).to(device)
    return numerator / denominator


def psnr_error(gen_frames, gt_frames, reduce_mean=True):
    """
    Computes the Peak Signal to Noise Ratio error between
    the generated images and the ground truth images.
    @param gen_frames: A tensor of shape [batch_size, 3, height, width].
                    The frames generated by the generator model.
    @param gt_frames: A tensor of shape [batch_size, 3, height, width].
                    The ground-truth frames for each frame in gen_frames.
    @return: A scalar tensor. The mean Peak Signal to Noise Ratio error
            over each frame in the batch.
    """

    shape = list(gen_frames.shape)
    num_pixels = (shape[1] * shape[2] * shape[3])
    gt_frames = (gt_frames + 1.0) / 2.0  # if the generate ouuput is sigmoid output, modify here.
    gen_frames = (gen_frames + 1.0) / 2.0
    square_diff = (gt_frames - gen_frames) ** 2
    batch_errors = 10 * log10(1. / ((1. / num_pixels) * torch.sum(square_diff, [1, 2, 3])))
    if reduce_mean:
        batch_errors = torch.mean(batch_errors)
    return batch_errors


def norm_scores(psnrs, sizes=None):
    '''
    Normalize psnrs in one folder
    '''
    if not isinstance(psnrs, np.ndarray):
        psnrs = np.array(psnrs)
    
    psnrs -= min(psnrs)
    psnrs /= max(psnrs)

    return psnrs


def calc_auc(total_scores, total_labels, pad=False):
    if not isinstance(total_scores, np.ndarray):
        flat = total_scores[0]
        for arr in total_scores[1:]:
            flat = np.concatenate([flat, arr], axis=-1)
        total_scores = flat
    if not isinstance(total_labels, np.ndarray):
        flat = total_labels[0]
        for arr in total_labels[1:]:
            flat = np.concatenate([flat, arr], axis=-1)
        total_labels = flat
    if pad: 
        total_scores = np.concatenate(([1], total_scores, [1]))
        total_labels = np.concatenate(([0], total_labels, [0]))

    fpr, tpr, th = metrics.roc_curve(total_labels, total_scores, pos_label=0)
    auc = metrics.auc(fpr, tpr)
    return auc


def _gaussian_filter(support, sigma):
    mu = support[len(support) // 2 - 1]
    filter = 1.0 / (sigma * np.sqrt(2 * math.pi)) * np.exp(-0.5 * ((support - mu) / sigma) ** 2)
    return filter


def gaussian_smooth(scores):
    filter_2d = _gaussian_filter(np.arange(1, 302), 21)   
    padding_size = len(filter_2d) // 2
    in_ = np.concatenate((np.ones(padding_size), scores, np.ones(padding_size)))
    scores = np.correlate(in_, filter_2d, 'valid')
    return scores